{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a71fdd3",
   "metadata": {},
   "source": [
    "# S07 — Safe Pick-Up Spots & Safety Geofences\n",
    "\n",
    "Генерируем **безопасные точки посадки** рядом с опасными зонами и строим **геозоны**\n",
    "на основе высоких значений SRI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./S00_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20df987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Загрузка SRI (edge) и hex features, если есть\n",
    "sri_edge = pd.read_parquet(SRI_EDGE_PARQUET) if SRI_EDGE_PARQUET.exists() else None\n",
    "edge_df = pd.read_parquet(EDGE_FEATURES_PARQUET) if EDGE_FEATURES_PARQUET.exists() else None\n",
    "hex_df = pd.read_parquet(HEX_FEATURES_PARQUET) if HEX_FEATURES_PARQUET.exists() else None\n",
    "print([e.shape if e is not None else None for e in [sri_edge, edge_df, hex_df]])\n",
    "if sri_edge is None:\n",
    "    raise SystemExit(\"Не найден SRI_EDGE. Запустите S06.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf74ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Геозоны: берём рёбра с SRI >= порога и строим буферы (упрощённо без геометрии используем точки из POINT_FEATURES)\n",
    "THR = np.nanpercentile(sri_edge[\"SRI\"], 85)  # топ-15% как опасные\n",
    "sri_edge[\"is_hot\"] = sri_edge[\"SRI\"] >= THR\n",
    "print(\"Hot edges:\", sri_edge[\"is_hot\"].mean())\n",
    "\n",
    "# Если есть matched точки — используем их как геом.представление для простого геоjson (центры кластеров)\n",
    "if MATCHED_PARQUET.exists():\n",
    "    mm = pd.read_parquet(MATCHED_PARQUET)\n",
    "    mm_join = mm.merge(sri_edge[[\"u\",\"v\",\"key\",\"is_hot\",\"SRI\"]], on=[\"u\",\"v\",\"key\"], how=\"inner\")\n",
    "    hot_pts = mm_join[mm_join[\"is_hot\"]][[\"lat\",\"lng\",\"SRI\"]].copy()\n",
    "else:\n",
    "    # Fallback: центры hex из HEX_FEATURES (требуется h3)\n",
    "    hot_pts = None\n",
    "\n",
    "# Экспорт упрощенного GeoJSON геозон как набор точек\n",
    "features = []\n",
    "if hot_pts is not None:\n",
    "    for _,r in hot_pts.sample(min(len(hot_pts), 5000), random_state=42).iterrows():\n",
    "        features.append({\n",
    "            \"type\":\"Feature\",\n",
    "            \"geometry\":{\"type\":\"Point\",\"coordinates\":[float(r[\"lng\"]), float(r[\"lat\"])]},\n",
    "            \"properties\":{\"SRI\": float(r[\"SRI\"])}\n",
    "        })\n",
    "    geo = {\"type\":\"FeatureCollection\",\"features\":features}\n",
    "    with open(GEOFENCES_GEOJSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(geo, f)\n",
    "    print(\"Saved geofences (points proxy):\", GEOFENCES_GEOJSON)\n",
    "else:\n",
    "    print(\"Не удалось сформировать геозоны (нет MATCHED и H3).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f03521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Safe Pick-Up генератор: выбираем кандидатов в радиусе 150 м от опасных точек,\n",
    "# среди участков с низким SRI (или низкой congestion), затем greedy покрытие.\n",
    "MAX_CANDIDATES = 2000\n",
    "RADIUS_M = 120.0\n",
    "\n",
    "if MATCHED_PARQUET.exists():\n",
    "    mm = pd.read_parquet(MATCHED_PARQUET)\n",
    "    # Признаки безопасности кандидата — низкая congestion/низкий SRI (если доступен)\n",
    "    base = mm.merge(sri_edge[[\"u\",\"v\",\"key\",\"SRI\"]], on=[\"u\",\"v\",\"key\"], how=\"left\")\n",
    "    base = base.dropna(subset=[\"SRI\"])\n",
    "    # Нормируем удобство: score = - alpha*SRI - beta*freeflow (если есть) + gamma* (доля стопов низкая)\n",
    "    cand = base[[\"lat\",\"lng\",\"SRI\"]].copy()\n",
    "    cand[\"score\"] = -0.8*cand[\"SRI\"]\n",
    "    # Оставим топ кандидатов по score\n",
    "    cand = cand.nsmallest(MAX_CANDIDATES, \"score\").reset_index(drop=True)\n",
    "\n",
    "    # Покрытие опасных точек\n",
    "    if hot_pts is not None and len(hot_pts) > 0:\n",
    "        import numpy as np\n",
    "        EARTH_R = 6_371_000.0\n",
    "        hot = hot_pts[[\"lat\",\"lng\",\"SRI\"]].copy()\n",
    "\n",
    "        # Пространственный индекс (быстро) или безопасный fallback без sklearn\n",
    "        try:\n",
    "            from sklearn.neighbors import BallTree\n",
    "            cand_rad = np.radians(cand[[\"lat\",\"lng\"]].values)\n",
    "            hot_rad  = np.radians(hot[[\"lat\",\"lng\"]].values)\n",
    "            tree = BallTree(hot_rad, metric=\"haversine\")\n",
    "            neighbors = tree.query_radius(cand_rad, r=RADIUS_M / EARTH_R)  # list[np.ndarray] на кандидата\n",
    "        except Exception:\n",
    "            # Без sklearn: предфильтруем по широте + векторная гаверсина по окну\n",
    "            cand_xy = cand[[\"lat\",\"lng\"]].to_numpy()\n",
    "            hot_xy  = hot[[\"lat\",\"lng\"]].to_numpy()\n",
    "            lat_tol = RADIUS_M / 111_000.0\n",
    "            order = np.argsort(hot_xy[:,0])\n",
    "            hot_sorted = hot_xy[order]\n",
    "            neighbors = []\n",
    "            for lat, lng in cand_xy:\n",
    "                lo, hi = lat - lat_tol, lat + lat_tol\n",
    "                i0 = np.searchsorted(hot_sorted[:,0], lo)\n",
    "                i1 = np.searchsorted(hot_sorted[:,0], hi)\n",
    "                if i1 <= i0:\n",
    "                    neighbors.append(np.array([], dtype=int))\n",
    "                    continue\n",
    "                clat, clng = np.radians([lat, lng])\n",
    "                block = np.radians(hot_sorted[i0:i1])\n",
    "                dlat = block[:,0] - clat\n",
    "                dlng = block[:,1] - clng\n",
    "                a = np.sin(dlat/2)**2 + np.cos(clat)*np.cos(block[:,0])*np.sin(dlng/2)**2\n",
    "                dist = 2*EARTH_R*np.arcsin(np.sqrt(a))\n",
    "                idx = order[i0:i1][dist <= RADIUS_M]\n",
    "                neighbors.append(idx)\n",
    "\n",
    "        covered = np.zeros(len(hot), dtype=bool)\n",
    "        chosen = []\n",
    "        for _ in range(min(10, len(cand))):\n",
    "            # прирост покрытия по каждому кандидату (без iterrows)\n",
    "            gains = np.fromiter(((~covered[idxs]).sum() for idxs in neighbors), dtype=int, count=len(neighbors))\n",
    "            best = int(gains.argmax())\n",
    "            if gains[best] <= 0:\n",
    "                break\n",
    "            chosen.append(cand.loc[best, [\"lat\",\"lng\",\"score\"]].to_dict())\n",
    "            covered[neighbors[best]] = True\n",
    "            neighbors[best] = np.array([], dtype=int)\n",
    "\n",
    "        # Экспорт\n",
    "        features = [{\n",
    "            \"type\":\"Feature\",\n",
    "            \"geometry\":{\"type\":\"Point\",\"coordinates\":[float(c[\"lng\"]), float(c[\"lat\"])]},\n",
    "            \"properties\":{\"score\": float(c[\"score\"])}\n",
    "        } for c in chosen]\n",
    "        geo = {\"type\":\"FeatureCollection\",\"features\":features}\n",
    "        with open(SAFE_PU_GEOJSON, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(geo, f)\n",
    "        print(\"Saved safe pick-ups:\", SAFE_PU_GEOJSON)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
