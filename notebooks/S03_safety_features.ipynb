{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65eef49f",
   "metadata": {},
   "source": [
    "# S03 — Safety Feature Engineering\n",
    "\n",
    "Строим фичи на уровнях **point / hex / edge**.  \n",
    "Опционально вычисляем **микро‑сегменты** (для HBR/HCT) в быстром приближении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./S00_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe09fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Загрузка исходных и (если есть) map-matched данных\n",
    "read_kwargs = dict(sep=\",\", engine=\"c\",\n",
    "                   dtype={\"randomized_id\":\"int64\",\"lat\":\"float64\",\"lng\":\"float64\",\"alt\":\"float64\",\"spd\":\"float64\",\"azm\":\"float64\"},\n",
    "                   header=0)\n",
    "try:\n",
    "    sample = pd.read_csv(DATA_PATH, nrows=5, **read_kwargs)\n",
    "    exp = [\"randomized_id\",\"lat\",\"lng\",\"alt\",\"spd\",\"azm\"]\n",
    "    if list(sample.columns[:6]) != exp:\n",
    "        read_kwargs.update({\"header\":None,\"names\":exp})\n",
    "except Exception:\n",
    "    read_kwargs.update({\"header\":None,\"names\":[\"randomized_id\",\"lat\",\"lng\",\"alt\",\"spd\",\"azm\"]})\n",
    "df = pd.read_csv(DATA_PATH, **read_kwargs)\n",
    "print(\"Base data:\", df.shape)\n",
    "\n",
    "mm = None\n",
    "if MATCHED_PARQUET.exists():\n",
    "    mm = pd.read_parquet(MATCHED_PARQUET)\n",
    "    print(\"Matched loaded:\", mm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31da3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Point-level features\n",
    "pt = (mm if mm is not None else df).copy()\n",
    "pt[\"spd_clip\"] = clip_series_by_quantiles(pt[\"spd\"].astype(float))\n",
    "pt[\"stop_flag\"] = pt[\"spd_clip\"] < CONFIG[\"STOP_SPEED_MS\"]\n",
    "pt[\"azm\"] = pt[\"azm\"] % 360.0\n",
    "if \"edge_bearing\" in pt.columns:\n",
    "    pt[\"bearing_dev\"] = angle_diff_deg(pt[\"azm\"], pt[\"edge_bearing\"])\n",
    "else:\n",
    "    pt[\"bearing_dev\"] = np.nan\n",
    "\n",
    "# alt residual: отклонение от локальной медианы (здесь — глоб. прибл. по кванти и затем z)\n",
    "alt_med = pt[\"alt\"].median()\n",
    "pt[\"alt_residual\"] = pt[\"alt\"] - alt_med\n",
    "\n",
    "# H3 hex id\n",
    "if h3 is not None:\n",
    "    res = CONFIG[\"H3_RES_HEX\"]\n",
    "    pt[\"h3\"] = [h3.geo_to_h3(lat, lng, res) for lat,lng in zip(pt[\"lat\"].values, pt[\"lng\"].values)]\n",
    "else:\n",
    "    pt[\"h3\"] = None\n",
    "\n",
    "# H3 hex id (v3/v4 compatible + safe for Parquet)\n",
    "try:\n",
    "    from h3 import h3 as h3lib   # v3\n",
    "except Exception:\n",
    "    try:\n",
    "        import h3 as h3lib       # v4\n",
    "    except Exception:\n",
    "        h3lib = None\n",
    "\n",
    "if h3lib is not None:\n",
    "    res = CONFIG[\"H3_RES_HEX\"]\n",
    "    to_cell = getattr(h3lib, \"geo_to_h3\", None) or getattr(h3lib, \"latlng_to_cell\", None)\n",
    "    cells = [to_cell(lat, lng, res) for lat, lng in zip(pt[\"lat\"].values, pt[\"lng\"].values)]\n",
    "    # Normalize to string for Parquet portability (avoids uint64 issues)\n",
    "    cell_to_str = getattr(h3lib, \"int_to_h3\", None) or getattr(h3lib, \"cell_to_str\", None)\n",
    "    pt[\"h3\"] = [cell_to_str(c) if cell_to_str else str(c) for c in cells]\n",
    "else:\n",
    "    pt[\"h3\"] = None\n",
    "\n",
    "# Сохраняем point features\n",
    "pt.to_parquet(POINT_FEATURES_PARQUET, index=False)\n",
    "print(\"Saved:\", POINT_FEATURES_PARQUET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Micro-segments (FAST_MODE): используем приближенную \"пространственную сортировку\"\n",
    "# В отсутствие времени упорядочим точки внутри ID по (lat,lng) сетке и возьмём пары соседей.\n",
    "FAST_MODE = True\n",
    "if FAST_MODE:\n",
    "    pts = pt[[\"randomized_id\",\"lat\",\"lng\",\"spd\",\"azm\"]].copy()\n",
    "    # Пространственный ключ: округление lat/lng до 5e-4 (~55 м), затем сортировки\n",
    "    pts[\"lat_b\"] = (pts[\"lat\"] / 5e-4).round().astype(int)\n",
    "    pts[\"lng_b\"] = (pts[\"lng\"] / 5e-4).round().astype(int)\n",
    "    pts = pts.sort_values([\"randomized_id\",\"lat_b\",\"lng_b\"]).reset_index(drop=True)\n",
    "\n",
    "    # Сдвиги на ±1 в этом порядке как кандидаты пар\n",
    "    for shift in [1]:\n",
    "        pts[f\"lat_next_{shift}\"] = pts[\"lat\"].shift(-shift)\n",
    "        pts[f\"lng_next_{shift}\"] = pts[\"lng\"].shift(-shift)\n",
    "        pts[f\"spd_next_{shift}\"] = pts[\"spd\"].shift(-shift)\n",
    "        pts[f\"azm_next_{shift}\"] = pts[\"azm\"].shift(-shift)\n",
    "        pts[f\"id_next_{shift}\"]  = pts[\"randomized_id\"].shift(-shift)\n",
    "\n",
    "    seg = pts[(pts[\"randomized_id\"] == pts[\"id_next_1\"])].copy()\n",
    "    seg[\"s_m\"] = [haversine_m(a,b,c,d) for a,b,c,d in zip(seg[\"lat\"],seg[\"lng\"],seg[\"lat_next_1\"],seg[\"lng_next_1\"])]\n",
    "    seg[\"bearing_pair\"] = [bearing_deg(a,b,c,d) for a,b,c,d in zip(seg[\"lat\"],seg[\"lng\"],seg[\"lat_next_1\"],seg[\"lng_next_1\"])]\n",
    "    seg[\"bearing_dev_pair\"] = angle_diff_deg(seg[\"azm\"], seg[\"bearing_pair\"])\n",
    "    # продольная перегрузка (без времени): (v2^2 - v1^2) / (2*s)\n",
    "    seg[\"a_long\"] = (seg[\"spd_next_1\"]**2 - seg[\"spd\"]**2) / (2.0 * seg[\"s_m\"].replace(0, np.nan))\n",
    "    # тройки для поперечной (упрощение: радиус через chord/angle)\n",
    "    # Оставим как future-work; для HCT используем кривизну ребра, если mm доступен.\n",
    "else:\n",
    "    seg = None\n",
    "\n",
    "print(\"Segments (approx) shape:\", None if seg is None else seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9008bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Edge-level агрегаты (если есть match)\n",
    "edge_df = None\n",
    "if mm is not None:\n",
    "    edge_cols = [\"u\",\"v\",\"key\",\"highway\",\"oneway\",\"length\"]\n",
    "    agg = pt.drop(columns=edge_cols, errors=\"ignore\").join(mm[edge_cols], how=\"left\")\n",
    "    # Метрики по скорости и стопам\n",
    "    g = agg.groupby([\"u\",\"v\",\"key\",\"highway\",\"oneway\"], dropna=False)\n",
    "    edge_df = g.agg(\n",
    "        n_obs=(\"spd_clip\",\"size\"),\n",
    "        n_ids=(\"randomized_id\", \"nunique\"),\n",
    "        p50_spd=(\"spd_clip\",\"median\"),\n",
    "        p85_spd=(\"spd_clip\", lambda s: s.quantile(0.85)),\n",
    "        p95_spd=(\"spd_clip\", lambda s: s.quantile(0.95)),\n",
    "        stop_rate=(\"stop_flag\",\"mean\"),\n",
    "        bearing_dev_mean=(\"bearing_dev\",\"mean\"),\n",
    "        dist2node_med=(\"dist2node\",\"median\")\n",
    "    ).reset_index()\n",
    "    edge_df[\"freeflow\"] = edge_df[\"p85_spd\"]\n",
    "    edge_df[\"congestion\"] = 1.0 - (edge_df[\"p50_spd\"] / edge_df[\"freeflow\"].replace(0,np.nan))\n",
    "    edge_df.to_parquet(EDGE_FEATURES_PARQUET, index=False)\n",
    "    print(\"Saved:\", EDGE_FEATURES_PARQUET)\n",
    "else:\n",
    "    print(\"Edge-level features skipped (no map-matching).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Hex-level агрегаты\n",
    "hex_df = None\n",
    "if pt[\"h3\"].notna().any():\n",
    "    g = pt.groupby(\"h3\")\n",
    "    hex_df = g.agg(\n",
    "        n_obs=(\"spd_clip\",\"size\"),\n",
    "        n_ids=(\"randomized_id\",\"nunique\"),\n",
    "        p50_spd=(\"spd_clip\",\"median\"),\n",
    "        p85_spd=(\"spd_clip\", lambda s: s.quantile(0.85)),\n",
    "        stop_rate=(\"stop_flag\",\"mean\"),\n",
    "        bearing_dev_mean=(\"bearing_dev\",\"mean\")\n",
    "    ).reset_index()\n",
    "    hex_df[\"freeflow\"] = hex_df[\"p85_spd\"]\n",
    "    hex_df[\"congestion\"] = 1.0 - (hex_df[\"p50_spd\"] / hex_df[\"freeflow\"].replace(0,np.nan))\n",
    "    hex_df.to_parquet(HEX_FEATURES_PARQUET, index=False)\n",
    "    print(\"Saved:\", HEX_FEATURES_PARQUET)\n",
    "else:\n",
    "    print(\"Hex-level features skipped (no h3).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
